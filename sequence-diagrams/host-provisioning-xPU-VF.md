# Host provisioning xPU VF/SF

The main idea behind this document is to specify the flow of VF/SF allocation from the Host POV if the networking infrastructure is provided by a xPU.

## Assumptions

- VFs/SFs are uniquely identified using `SerialNum/PF_id/VF_id`. This is needed to track VFs/SFs as they move through networking namespaces (if_index is not unique).

- The same scenario will work for both Single Cluster or Multi-cluster.

- This will work for primary or secondary networking.

- Selectors will be used to decide worker nodes to apply the CRDs to.

- Service metrics will be collectable through services that are fully integrated
as a Kubernetes deployment.

- The Kublet will be host networked.

- The infrastructure is the `primary` entity driving/making networking decisions on behalf of the host.

## Opens

- If the infra cluster needs access to many Kubernetes resources in the tenant cluster, does it make sense to have a broker or is direct cluster access a better approach and does a broker architecture scale well across clusters when many of the resources that need to be shared are Kubernetes resources.
- Should we even consider using something like microshift on the DPU in the two cluster scenario.
- Need to think about how nodeport will work.
- How to use CNI in hetrogenous deployments.

### To Broker or not to Broker?

A **Broker** is an entity that syncs OPI CRDs between the Tenant and Infra clusters. It's a singleton component that is deployed on a cluster whose Kubernetes API must be accessible by all of the participating clusters. The Broker cluster may be one of the participating clusters or a standalone cluster without the other components deployed. The Agent components deployed in each participating cluster are configured with the information to securely connect to the Broker clusterâ€™s API.

The xPU Kubernetes architecture will avoid leveraging a Broker within the xPU as the infra cluster and the tenant cluster are tightly coupled. The infra cluster will need a access to several Kubernetes resources and it does not make sense to replicate these (resources) through CRDs via a Broker. There's also a question of latency introduced by the Broker and whether or not it can scale.

### Provisioning Entities and roles

- **xPU Host Agent**
  - CRUDs OPI CRDs (from the Kube-apiserver or the Broker).
  - Processes requests from the Device Plugin or CNI via a gRPC server.
- **xPU Agent**
  - CRUDs OPI CRDs (from the Kube-apiserver or the Broker).
  - Translates those CRDs into OPI API calls (which it also invokes).
  - Monitors Kubernetes resources in the tenant cluster.
  - Translates those K8s resources into OPI API calls (which it also invokes).
- **Device Plugin**:
  - Provisions and advertises the VFs/SFs to Kubernetes.
  - Interacts with the xPU Host agent to invoke the creation of OPI netdev CRDs
    on Pod allocation.
- **CNI**:
  - Configures the interface with the allocated IP address
  - Moves the VF/SF from the Host network namespace to the Pod Network namespace
   (vice versa).

### Required Resources

TODO (WIP)

- Netdev CRD (New)
- Service: reflecting the services in the tenant cluster.
- EndpointSlice: reflecting the endpoint slices in the tenant cluster.
- Network policy: reflecting the network policies in the tenant cluster.

### Single Cluster sequence diagrams

TODO

### Multi Cluster sequence diagrams

#### Initialization

The following high level diagram provides an overview of the initialization of the entities involved in provisioning an xPU VF to a host.

![host-provisioning-initialization](./images/host-provisioning-xPU-VF-init.png)

The following high level diagram provides an overview of the entities working
together to provision a secondary network interface for a pod.

TODO

#### Pod Creation

![host-provisioning-pod-creation](./images/host-provisioning-xPU-VF-pod-creation.png)

#### Pod Deletion

![host-provisioning-pod-deletion](./images/host-provisioning-xPU-VF-pod-deletion.png)

## CRDs

### DPUNetworkNodeState

```yaml
TODO WIP
```

References

- [1 Liveliness probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
- [2 Configuring dpu devices](https://docs.openshift.com/container-platform/4.12/networking/hardware_networks/configuring-dpu-device.html)
